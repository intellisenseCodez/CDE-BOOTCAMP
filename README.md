# Projects 

01. ## [COREHEALTH DATA PIPELINE DESIGN](https://github.com/intellisenseCodez/CDE_BOOTCAMP/tree/main/01_Fundamental_of_Data_Engineering).

![Home page](./01_Fundamental_of_Data_Engineering/images/1.jpg)

### Overview
This capstone project is designed to reinforce the understanding of the core components of an end-to-end data pipeline. The focus is on conceptualizing and designing a comprehensive data pipeline that addresses data ingestion, processing, storage, and analysis. The project challenges apply theoretical knowledge to a practical scenario without the need to build or code the actual pipeline.

In this project i show case my knowledge on the fundamental of data engineering and designing data pipeline system base on some scenerio.

## Tools Used
1. Canvas
2. Draw.io
3. Google Images

Click [for more details](https://github.com/intellisenseCodez/CDE_BOOTCAMP/tree/main/01_Fundamental_of_Data_Engineering)

02. ## [SIMPLE ETL PIPELINE USING BASH SCRIPTING](https://github.com/intellisenseCodez/CDE_BOOTCAMP/tree/main/02_cde_linux_git_assignment).

!["System Design"](/02_cde_linux_git_assignment/images/system_design.png)

## Overview
This project involves building a simple ETL Pipeline using linux commands and bash scripting. As a Data Engineer at CoreDataEngineer i was tasked with creating bash script that performs a simple ETL process on a given CSV file. The bash script is to download the CSV file from a source, perform a simple transformation and load the transformed data into a final directory.

In this project i showcased my knowledge on building a virtual development environment using the vagrant tool. I also display my strength on the understanding on Linux commands and Bash Scripting as a data engineer.

## Tools Used
1. Vagrant
2. Oracle Virtial Box
3. Git (Version Control System)
4. Code Editor (any of your choice). My favorite is Visual Studio Code ðŸ˜Š.

Click [for more details](https://github.com/intellisenseCodez/CDE_BOOTCAMP/tree/main/02_cde_linux_git_assignment)

